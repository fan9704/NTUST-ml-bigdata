# W11 超參數調教與深度學習

---

## 超參數調教

- 調整「超參數（Hyperparameters）」來提升模型效能的過程
- 與模型在訓練過程中學習到的「參數（Parameters）」不同，超參數需在訓練前決定

| 類型 | 說明 | 範例 |
| --- | --- | --- |
| 模型參數(model parameters)| 由訓練資料自動學習得到 | 線性回歸中的權重 w 和偏差 b |
| 超參數(hyperparameters) | 需在訓練前人工設定，影響學習過程 | 學習率 learning_rate、樹的深度 max_depth，KNN 的鄰居數 k |

----

### 常見超參數範例

- 線性回歸
    - 正則化強度 alpha（Lasso/Ridge）
- 決策樹
    - max_depth、min_samples_split
- SVM
    - C（誤差容忍度）、gamma（核函數參數）
- KNN
    - n_neighbors、距離計算方式
- 隨機森林
    - n_estimators（樹數）、max_features
- XGBoost
    - learning_rate、n_estimators、max_depth、subsample、colsample_bytree

### 調參方法

- Grid Search（網格搜尋）
    - 枚舉所有可能的參數組合
    - 優點：全面
    - 缺點：耗時
- Random Search（隨機搜尋）
    - 隨機抽樣參數組合
    - 常常比 Grid Search 更有效率
    - 可指定抽樣次數
- Bayesian Optimization（貝葉斯最佳化）
    - 是一種基於機率模型（通常是高斯過程 Gaussian Process）的最佳化方法
    - 它會預測哪些超參數組合可能效果好，並優先測試這些組合，從而比 Grid Search 或 Random Search 更有效率
- CV交叉驗證（Cross Validation）
    - 調參時搭配使用
    - 將資料切成多份，反覆訓練與驗證，避免過擬合
    - 常見：K-Fold CV

### 程式實作

```python
from sklearn.model_selection import GridSearchCV
param_grid = {    
    "n_estimators": [50, 100],     
    "max_depth": [3, 5],  
    "learning_rate": [0.05, 0.1]
}
grid_model = GridSearchCV(XGBClassifier(use_label_encoder=False,eval_metric="logloss"), param_grid, cv=3)
grid_model.fit(X_train, y_train)
grid_best_score = grid_model.best_score_

from sklearn.model_selection import RandomizedSearchCV
param_dist = {    
    "n_estimators": randint(50, 150),    
    "max_depth": randint(3, 10),    
    "learning_rate": uniform(0.01, 0.2)
}
random_model = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric="logloss"), param_dist, n_iter=20, cv=3, random_state=42)
random_model.fit(X_train, y_train)
random_best_score = random_model.best_score

# !pip install optuna
import optuna
def objective(trial): 
    model = XGBClassifier(        
        n_estimators=trial.suggest_int(“n_estimators”, 50, 200),        	
        max_depth=trial.suggest_int(“max_depth”, 3, 10),        
        learning_rate=trial.suggest_float(“learning_rate”, 0.01, 0.2, log=True),        
        use_label_encoder=False,       
        eval_metric=“logloss”   
    )    
    model.fit(X_train, y_train)    
    preds = model.predict(X_test)    
    return accuracy_score(y_test, preds)
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=30)
bayes_best_score = study.best_value
```

---

## 神經網路（Neural Network）

- 神經網路（Neural Network, 簡稱 NN）是一種模仿人類大腦神經元運作方式設計的數學模型，主要用於從資料中學習，並且可以用來解決分類、回歸、生成、預測等問題
- 神經網路模仿人腦學習與記憶的方式，具有強大的預測能力
- 能夠捕捉輸入變數與輸出變數之間非常複雜的關係
- 基本結構由神經元（Neurons）組成，並分為三種層級：
    - 輸入層（Input Layer）： 接收資料
    - 隱藏層（Hidden Layers）： 進行資料運算與特徵抽取 是模型的主要運算區域
    - 輸出層（Output Layer）： 產生最終預測或分類結果
    
### 神經元

- 激活函數：
    - 激活函數引入非線性特性，使模型可以擬合複雜關係
    - 沒有激活函數，整個網路只是一個線性模型（即使堆了很多層）
- 神經元是一個「接收輸入、加權求和、非線性處理、產生輸出」的基本計算單位
 
### 激活函數（Activation Function）

- ReLU：只保留正值
- Sigmoid：將輸出限制在 0 到 1 之間
- Tanh：輸出範圍在 -1 到 1

### 神經網路的運作方式

- 前向傳播（Forward Propagation）
    - 每個神經元會將輸入資料乘上權重（Weight），加上偏差值（Bias），然後經過激活函數（Activation Function）產生輸出
- 前向傳播（Forward Propagation）
    - 比較預測結果與真實值之間的誤差
    - 根據誤差，調整每條連接的權重和偏差值，以最小化損失函數（Cost Function）
    
### 解決 Overfitting 的方法

- 提早停止（Early Stopping）
    - 特別適用於神經網路
    - 當驗證集誤差不再下降時就停止訓練，避免過度學習
- Dropout（隨機忽略神經元）
    - 適用於神經網路
    - 訓練時隨機忽略部分神經元，避免神經元過度依賴彼此
    
### 程式實作

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
# 建立模型
model = Sequential()
model.add(Input(shape=(X_train.shape[1],)))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# 編譯模型
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 訓練模型
history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)
```

---

## 深度神經網路（DNN）

- 神經網路又稱人工神經網路（Artificial Neural Network, ANN）
- 深度神經網路 （Deep Neural Network, DNN）
    - DNN 指的是擁有多層隱藏層的人工神經網路（ANN）
    - 與傳統神經網路（只有一層隱藏層）相比，DNN 的「深度」使得它能夠學習更複雜的資料結構與非線性關係

### 深度學習模型

- DNN 是深度學習的基礎模型框架，其他模型是在 DNN 基礎上的「專用化演化版」

| 模型類型 | 差異與演化方向 |
| --- | --- |
| CNN(卷積神經網路) | 全連接層改成卷積層(Convvolutional Layer)，擅長抓取圖像空間結構(如邊緣、紋理) |
| RNN/LSTM/GRU | 為了處理時間序列與序列資料，引入記憶機制與『時間布(timestep)』概念 |
| Transformer/BERT/GPT | 雖放棄 RNN 的時間遞迴，但仍基於深層結構與自注意力機制(Self-Attention)，本質仍為多層神經網路 |
| Autoencoder | 由兩個 DNN 組成，一個編碼器(Encoder)、一個解碼器(Decoder)，用於壓縮與重建資料 |
| GAN(生成對抗網路)|包含兩個神經網路(生成器 G + 判別器 D)，透過對抗方式訓練，實現資料生成能力 |

#### 卷積神經網路(CNN)

- 廣泛應用於圖像辨識、影像分類、物件偵測等領域
- 相較於全連接神經網路，CNN 更能處理圖像中的空間關係
- 特徵自動學習能力強，無需手動設計影像特徵
- CNN 的基本架構
    - 卷積層（Convolutional Layer）：提取局部特徵
    - 激活函數（如 ReLU）：引入非線性
    - 池化層（Pooling Layer）：降維、去除噪音
    - 全連接層（Fully Connected Layer）：進行分類或回歸
    - 輸出層（Output Layer）：通常搭配 softmax 或 sigmoid
- 卷積層的功能
    - 卷積核（Filter）會在圖像上滑動，提取局部特徵
    - 每個卷積核可學習不同的視覺模式（如邊緣、角落）
    - 卷積操作為加權求和：output = ∑ (input × filter)
- 池化層的功能
    - 主要目的是降維與提高不變性
    - 常見類型：
        - 最大池化（Max Pooling）：取區域內最大值
        - 平均池化（Average Pooling）：取區域平均值

##### 程式實作

```python
# !pip install tensorflow
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
# 建立 CNN 模型
model = models.Sequential()
model.add(layers.Input(shape=(28, 28, 1)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

```

#### 遞迴神經網路（RNN）

- 是一種具有「記憶功能」的神經網路
- 適用於序列資料：例如文字、語音、股價、感測器資料等
- 會將前一個時間點的輸出作為下一個時間點的輸入之一
- 可以學習時間上的依賴關係
- RNN 面臨的挑戰
    - 訓練困難：梯度消失或爆炸
    - 記憶能力有限：無法有效學習長期依賴
    - 對於長句子或長時間序列預測不佳
    
#### LSTM（Long Short-Term Memory）

- 是為了解決 RNN 的長期記憶問題而設計的
- 引入「記憶單元」與「三個閘門」來控制資訊流
- 能夠保留長期依賴資訊，適合處理較長的序列
- LSTM 的結構
    - 遺忘閘門（Forget Gate）：決定哪些資訊需要遺忘
    - 輸入閘門（Input Gate）：決定哪些新資訊加入記憶
    - 輸出閘門（Output Gate）：控制記憶的輸出
- 記憶單元狀態透過這三個閘門更新與傳遞

#### GRU（Gated Recurrent Unit）

- 是 LSTM 的簡化版本，運算更快、結構更簡單
- 合併了輸入與遺忘閘門為「更新閘門」
- 合併記憶單元與隱藏狀態，參數更少
- 在某些任務上表現與 LSTM 相近甚至更好
- GRU 的結構
    - 更新閘門（Update Gate）：控制當前狀態保留多少過去資訊
    - 重置閘門（Reset Gate）：決定如何結合新輸入與舊狀態
    - GRU 沒有額外的記憶單元，計算效率較高

#### RNN / LSTM / GRU 比較

| 模型 | 是否能記憶長期依賴 | 計算複雜度 | 應用場景 |
| --- | --- | --- | --- | 
| RNN | 差 | 最低 | 短記憶需求 |
| LSTM | 強 | 較高 | 長文、語音、機器翻譯 |
| GRU | 中等~強 | 中等 | 類似 LSTM，但訓練速度較快 |

- 應用場景
    - 語音辨識（Speech Recognition）
    - 機器翻譯（Machine Translation）
    - 股票預測、溫度預測（Time Series Forecasting）
    - 聊天機器人、語意理解（Chatbots, NLP）

##### 程式實作

```python
from tensorflow.keras.layers import LSTM
# 建立模型
model = Sequential()
model.add(LSTM(64, return_sequences=False, input_shape=(time_steps, 1)))
model.add(Dense(future_steps))
model.compile(optimizer='adam', loss='mse')
# 訓練模型
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))
# 模型預測（測試集）
predicted = model.predict(X_test)
predicted_inverse = scaler.inverse_transform(predicted)
real_inverse = scaler.inverse_transform(y_test)

```