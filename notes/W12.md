# W12 強化學習, 模型誤差與倫理

---

## 深度神經網路(DNN)

### Transformer

- Transformer 是一種深度學習架構，特別擅長處理序列資料（如文字、語音）
    - 由 Google 在 2017 年論文《Attention is All You Need》中提出
    - 捨棄了傳統的 RNN、LSTM 結構
    - 一種 Seq2Seq（Sequence-to-Sequence）模型架構
- Seq2Seq 是指「輸入一個序列，輸出另一個序列」的任務
- 關鍵技術
    - Transformer 的關鍵技術是「自注意力機制（Self-Attention）」
    - 能讓模型「同時」看整個輸入序列中所有詞彙間的關係
    - 不需要像 RNN 一樣逐步處理，實現高效率並支援平行運算
    - 每個輸入詞會與序列中其他詞計算關聯性，動態調整加權資訊
    - 搭配位置編碼（Positional Encoding） 補償模型無法辨識順序的問題


#### 架構概覽

- Transformer 通常由 Encoder 與 Decoder 組成：
    - Encoder： 接收輸入序列，透過多層 Self-Attention 編碼成上下文表示（contextual representation）
    - Decoder： 接收 Encoder 的輸出，並根據前一步的輸出生成目標序列
- 現今廣泛應用於 NLP (Natural Language Processing, 自然語言處理) 、語音、影像等領域
- 基於 Transformer 架構的知名模型
    - BERT 採用 Transformer 的 Encoder 架構
    - GPT 採用 Transformer 的 Decoder 架構

#### 應用與優勢

- 為什麼 Transformer 成為主流？
    - 比 RNN/LSTM 更快，支援平行運算
    - 能夠捕捉長距離依賴關係
    - 架構彈性，易於擴展到大型模型（如 GPT-4）
    - 應用廣泛：機器翻譯、語音辨識、對話系統、圖像處理、醫療預測等

### BERT

Google 在 2019 年 10 月正式宣布，將 BERT 模型導入 Google Search 排序演算法，用於更好地理解使用者查詢的語意

- BERT（Bidirectional Encoder Representations from Transformers）是由 Google 在 2018 年提出的語言表示模型
    - 基於 Transformer 架構，只使用 Encoder 部分
    - 名稱中的「Bidirectional」表示：同時考慮上下文的左右兩邊資訊
    - 能夠產生深層語意表示，為 NLP 任務帶來突破性成果

#### 核心原理

- BERT 的預訓練過程依靠兩大任務：
    - Masked Language Model（MLM）
        - 隨機遮蔽輸入句子中的字詞（如 [MASK]）
        - 模型學習根據上下文「猜」回被遮蔽的字
    - Next Sentence Prediction（NSP）
        - 判斷兩個句子是否為上下相連的語意
        - 段落增強模型對於句與句之間語意關聯的理解
- 應用範例：
    - 情感分析： 預測評論情緒正負
    - 問答系統： 根據問題從文章中找答案
    - 文字分類： 垃圾郵件分類、新聞主題判斷

#### 參數數量（以官方模型為例）

BERT 是一種預訓練語言模型，其訓練目標是先在大規模語料（如 Wikipedia、BooksCorpus）上進行通用語言理解的學習，之後再透過微調（fine-tuning） 應用在各種 NLP 任務上

| 模型名稱 | 層數(Layers) | 注意力頭數(Heads) | 隱藏層維度(Hidden Size) | 參數數量 |
| --- | --- | --- | --- | --- |
| BERT-Base | 12 | 12 | 768 | 約 1.1 億 |
| BERT-Large | 24 | 16 | 1024 | 約 3.4 億 |

### GPT

- GPT（Generative Pre-trained Transformer）
    - OpenAI 開發的生成式語言模型
    - 基於 Transformer 架構的 Decoder-only 結構
    - 使用大量網路語料進行預訓練，學習語言規則與知識
    - 可以根據輸入的提示文字，自動生成自然語言內容
    - 不需要專為每個任務設計模型，可透過「提示詞（Prompt）」應對不同任務
- 應用範圍非常廣
    - 自然語言生成（寫作輔助、自動摘要）
    - 對話系統（客服機器人、ChatGPT）
    - 程式碼產生（如 GitHub Copilot）
    - 語意理解與問答系統
    - 翻譯與改寫句子
    - 創意應用（詩詞、小說、劇本、笑話等）

#### GPT 系列模型一覽

| 模型版本 | 發表年份 | 參數數量 | 特點說明 |
| --- |---| --- | ---|
| GPT-1 | 2018 | 1.1 億 | 初版，證明預訓練有效性 | 
| GPT-2 | 2019 | 15 億 | 發展出驚人文本生成能力，但曾因風險為全面開源 |
| GPT-3 | 2020 | 175 億 | 支援少量學習(few-shot learning)，應用廣泛 |
| GPT-3.5 | 2022 | 約 200 億 | ChatGPT 初版背後模型，效能進一步提升 |
| GPT-4 | 2023 | 未公開 | 多模態能力(文字、圖像理解)，語言理解更深層 |

### Hugging Face

- 致力於人工智慧與自然語言處理（NLP）領域的開源平台與社群
    - https://huggingface.co/
    - 成立於 2016 年，最初是一個聊天機器人開發公司，現已成為全球最知名的 AI 模型平台之一
    - 目標是讓每個人都能輕鬆使用最先進的 AI 技術
    - 提供上千個預訓練模型，涵蓋 NLP、視覺、語音等任務

#### 主要功能

- Transformers
    - 開源套件，支援 BERT、GPT、T5 等主流模型
- Datasets
    - 提供大量開放語料庫，便於機器學習訓練
- Tokenizers
    - 高效的分詞工具，支援 BPE、WordPiece 等演算法
- Hub
    - 模型與資料集的集中平台（如 GitHub for AI）
- Spaces
    - 建立與展示 ML 應用的 Web App 平台

### Autoencoder（自編碼器）

- Autoencoder 是一種無監督學習的神經網路模型，目的是將輸入資料壓縮（編碼）後再還原（解碼）回原來的資料
- 架構組成：
    - 編碼器（Encoder）： 將輸入資料轉換為低維表示（潛在向量 latent vector）
    - 解碼器（Decoder）： 根據潛在向量重建出原始資料
- 訓練目標：
    - 最小化輸入與輸出之間的重建誤差（如 MSE）
- 常見用途：
    - 資料降維（如 PCA 替代）
    - 圖像去雜訊（Denoising）
    - 特徵學習（Feature Learning）
    - 異常偵測（Anomaly Detection）
- 自編碼器不需要標籤資料
- 是一種自我監督學習（self-supervised learning）

### VAE（變分自編碼器）

- VAE（Variational Autoencoder）是具有機率特性的 Autoencoder，能夠進行生成式學習
    - 可視為 AutoEncoder 的進階版
    - 與 AutoEncoder 不同之處在於 VAE 在編碼過程增加了一些限制，迫使生成的向量遵從高斯分佈。由於高斯分佈可以通過其 mean 和 standard deviation 進行參數化，因此 VAE 理論上是可以讓你控制要生成的圖片

### GAN（Generative Adversarial Network，生成對抗網路）

- GAN是一種生成式深度學習模型，由兩個神經網路互相對抗學習
    - 由 Ian Goodfellow 等人在 2014 年提出
    - 適用於生成逼真的圖片、音訊、文本等資料
    - 屬於無監督學習的一種應用
- GAN 的核心結構
    - GAN 包含兩個對抗角色：
        - 生成器（Generator, G）：接收隨機噪聲，嘗試生成看起來像真實資料的「假資料」
        - 判別器（Discriminator, D）：接收資料，判斷是真實資料還是生成器造出的假資料
    - 兩者在訓練過程中彼此對抗，最終使生成器能產生以假亂真的資料

#### GAN 的核心結構

- Generator 的目標： 騙過 Discriminator，讓假資料看起來更真
- Discriminator 的目標： 準確判斷真假資料
- 這種對抗結構讓 Generator 不斷進步

#### GAN 應用場景

- 圖像生成			：產生看起來真實的人臉（如 StyleGAN）
- 圖像修復（Inpainting）		：修補破損、模糊、遮蔽的圖片區域
- 風格轉換（Style Transfer） 	： 把照片變成畫風（如梵谷、浮世繪）
- 圖像超解析（Super Resolution）	： 把模糊圖片變清晰（如 SRGAN）
- 虛擬人臉/角色生成		： 創造虛構人物、動畫角色
- 影片生成/補幀			： 生成新影片幀或提升影片解析度
- 虛擬試衣/AI 換臉			： 將衣服或臉套用到目標人物身上
- 醫學影像合成			： 生成類似病灶的 MRI、X-ray 圖像
- 資料增強（Data Augmentation） 	： 對小樣本資料做出類似樣本以增強訓練效果

---

## 強化學習（Reinforcement Learning）

- 特點：基於獎勵機制，透過試誤學習最佳策略，常應用於決策控制問題

| 演算法 | 應用類型 | 說明 |
| --- | --- | --- |
| Q-learning | 強化學習 | 無模型學習方法，用於機器人控制，遊戲 AI |
| 深度 Q　網路(DQN,Deep Q-Network)| 強化學習 | 結合深度學習的 Q-learning，適用於 Atari 遊戲、金融交易。|
| 策略梯度(Policy Gradient) | 強化學習 | 透過學習策略來最大化獎勵，如自動架式、圍棋 AI(AlphaGo)。 |
| A3C(Asynchronous Advantage Actor-Critic) | 強化學習 | 增加版強化學習，適用於即時策略優化，如機器人動作學習。|

- Agent（代理人）
    - 做出決策的實體，例如機器人、AI 玩家
- Environment（環境）
    - Agent 所處的世界，例如遊戲場景
- State（狀態）
    - 環境目前的資訊，如遊戲畫面
- Action（行動）
    - Agent 能選擇的動作，如前進、跳躍
- Reward（獎勵）
    - 行動的即時回饋，如贏得分數或被扣分
- Policy（策略）
    - 根據狀態選擇行動的方式

### 運作流程

- Q-learning 是一種基本的強化學習方法，用來學習每個狀態-動作的期望回報值（Q 值）
- Deep Q-Learning（DQN） 則是將 Q-learning 的 Q 表，用神經網路來逼近，能解決狀態空間很大的問題，例如 Atari 遊戲、機器控制

### 關鍵倫理原則

| 原則 | 內容說明 |
| --- | --- |
| 公平性(Fairness) | 模型不得產生種族、性別等不公平結果 |
| 可解釋性(Explainability) | 決策邏輯應可被人類理解與檢視 |
| 隱私保護(Privacy) | 使用者資料須合法收集、使用、儲存 |
| 問責性(Accountability) | 自動化決策錯誤須可追溯、可調查責任方 |
| 安全性(Security) | 模型須防止遭竄改或濫用，並具備防護機制 |