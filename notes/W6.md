# W6 監督式學習分類演算法

---

## 邏輯迴歸(Logistic Regression)

- 用來做二元分類(binary classification)問題
- 屬於分類演算法，背後使用「機率迴歸」模型推估，保留迴歸一詞
- 輸出機率是(0~1) 超過 0.5 分類為 1 小於為 0
- 優點: 模型簡單易懂可解釋性高


### 數學原理

- 不是直接預設機率 p 而是假設對數勝算(log-odds) 是輸入的縣性函數

1. 機率 > 勝算(odds)
    - 如果某事件發生機率為 p -> odds = p/(1-p)
2. 勝算 > 對數勝算(logit)
    - 我們對勝算取 ln 得到對數勝算 logit(p) = ln(p/(1-p))
    - logit 好處是輸出範圍為(-inf,inf) 這樣就可以用線性模型來表示
3. 從對數勝算還原機率
    - logit(p) = ln(p/(1-p)) = w0 +w1X => p/(1-p) = e^(w0+w1x) => p = e(w0+w1x)/(1+e^(w0+w1x)) -> 1/(1+e^-(w0+w1X))

- Sigmoid 函數
    - 可以將任何時數轉成 0~1 之間的機率
    - S(X) = 1/ (1+e^-x)

### 損失函數/成本函數

- 使用 Binary Cross-Entropy 作為損失函數
    - L = -[ylog(y^) + (1-y) log(1-y^)]
- 總體 cost function(對所有資料取平均)
    - J(w) = -1/N sigma(1~n) [y^i log(y^i) + (1-y^(i) log(1-y^i))]
- 使用梯度下降法(Gradient Descent) 來最小化這個 cost function，進而學到最佳的權重 w 與截距 b

### 分類模型評估方法

- 混淆矩陣(Confusion Matrix)
    - 是個 2x2 表格(對二元分類來說)，用來呈現模型在測試資料上的分類結果
- 準確率(Accuracy)
    - 整體正確預測比率 Accuracy = (TP+TN)/(TP+TN+FP+FN)
- 精確率(Precision)
    - 預測為正類中，實際為正類的比例 Precision = TP/(TP + FP)
- 召回率(Recall/Sensitivity)
    -  實際正類中，被正確預測為正類的比例 Recall = TP/(TP + FN)
- F1 分數(F1 Score)
    - Precision 與 Recall 的加權平均，是兩者的平衡指標 F1 = 2 (Precision X Recall) / (Precision + Recall)

### ROC 曲線與 AUC 值

- ROC 曲線(Receiver Operating Characteristic)
    - 繪製 True Positive Rate(Recall) 對 False Positive Rate(FPR) 的圖
    - FPR 全名是 False Positive4 Rate(偽陽性率)，是用來衡量模型在分類中錯誤地把「負類」預測成「正類」的比例

FPR = FP / (FP + TN)

- AUC(Area Under Curve)
    - ROC 曲線下的面積，範圍在 0 到 1 之間
    - 越接近 1 表示模型越好， AUC = 0.5 等從隨機猜測

#### Precision & Recall 的 Trade-off 

- Precision 命中率
- Recall 抓全率